# TeamBlind Interview Post Summaries - Batch 03

## Meta E4 ML System Design Interview
**URL:** https://www.teamblind.com/post/meta-e4-ml-system-design-interview-qnkhbgfn
**Summary:** A candidate preparing for a Meta E4 ML Engineer onsite asks for tips and resources for the ML system design interview round. The E4 onsite loop includes 2 coding rounds, 1 ML design round, and 1 behavioral round. Community members share study resources and note that Meta questions typically involve variations on recommendation systems or harmful content detection.
**Interview Questions Mentioned:**
- ML system design involving recommendation systems
- Harmful content detection/classification system design
- LeetCode-style coding (top 150 tagged questions)
**Key Insights:**
- Alex Xu's "Machine Learning System Design Interview" book is highly recommended for this round
- Chip Huyen's "Designing Machine Learning Systems" is considered sufficient preparation for E4 level
- Meta ML system design questions tend to focus on recommendation systems and content moderation
- Coding rounds may be AI/ML-flavored or standard LeetCode depending on the specific role

---

## Meta E6 MSL Research Engineer Interview
**URL:** https://www.teamblind.com/post/meta-e6-msl-research-engineer-interview-8rx0rykv
**Summary:** A candidate interviewing for E6 Research Engineer in Meta's MSL (Machine Learning Systems and Libraries) team discusses the interview format. The recruiter indicated there would be two "AI Coding" interviews in the full loop, which is somewhat unusual. The community discusses typical E6 interview structure and compensation expectations.
**Interview Questions Mentioned:**
- AI Coding rounds (math/stats-flavored coding questions)
- AI System Design round
- Behavioral questions using STAR method (challenging situations, hard problems, mistakes, conflicts)
**Key Insights:**
- E6 interview loop typically consists of 2 coding, 2 system design, and 1 behavioral round
- "AI Coding" rounds add math/stats flavor to standard coding problems
- Candidates should prepare 6-8 stories for behavioral using STAR method
- Compensation at this level is approximately $450k total compensation

---

## Meta IC5 ML Engineer Interview with Just Coding Rounds
**URL:** https://www.teamblind.com/post/meta-ic5-ml-engineer-interview-with-just-coding-rounds-usmsyl54
**Summary:** A candidate was told their IC5 (E5-equivalent) ML Engineer interview would consist of only coding rounds after the initial screen, which seemed unusual. The community discusses how interview structure varies by role and team, with most candidates reporting a more typical mix of coding, design, and behavioral rounds.
**Interview Questions Mentioned:**
- Phone screen: 2 LeetCode medium questions in 45 minutes
- Onsite coding: 2 medium LC questions per round, with some rounds including medium-hard
- ML system design (recommendation systems)
- Product architecture round
**Key Insights:**
- Interview structure can vary significantly by team and specific role at Meta
- The typical loop is 1 system design, 1 ML system design, 2 coding, and 1 behavioral
- Some teams may deviate and focus more heavily on coding
- Always confirm the exact interview format with your recruiter

---

## Meta M2 Interview - ML
**URL:** https://www.teamblind.com/post/meta-m2-interview-ml-nvdnpzny
**Summary:** A candidate preparing for a Meta M2-level (engineering manager) interview for an AI/ML Engineering Leadership role discusses the interview structure. The initial rounds include one with a director for the People Module and one on the technical module (ML design). The post seeks advice on preparation strategies for management-track ML interviews.
**Interview Questions Mentioned:**
- People Module: leadership, conflict resolution, team growth, providing guidance
- Technical Module: ML system design
- Onsite: Leadership & People Management (2 rounds), system design, behavioral
**Key Insights:**
- M2 interview has distinct "People Module" and "Technical Module" components
- The onsite consists of five or six 45-minute interviews back-to-back
- At Meta, managers are expected to say they "support" their team rather than "manage" them
- Candidates should demonstrate ability to delegate consequential technical decisions to their team
- Heavy emphasis on cross-functional partnerships and engineering culture

---

## Meta Machine Learning Engineer Interview Prep
**URL:** https://www.teamblind.com/post/Meta-Machine-Learning-Engineer-interview-prep-qympPAHi
**Summary:** A candidate seeking preparation advice for a Meta MLE interview receives community recommendations covering all four major interview areas: algorithms, systems design, ML questions, and behavioral. The discussion covers the full interview pipeline from phone screen to onsite and highlights key resources.
**Interview Questions Mentioned:**
- Phone screen: 2 LeetCode questions
- Onsite: 2 LeetCode rounds, 1 ML design round, 1 system design round, 1 behavioral round
- ML system design (recommendation systems, content ranking)
**Key Insights:**
- Interview covers 4 areas: algorithms, systems design, ML questions, and behavioral
- Recommended resources include Facebook ML Field Guide and Educative.io ML system design course
- "Grokking the Machine Learning Interview" and "Machine Learning Design Patterns" book are also useful
- Coursera's "Machine Learning Engineering for Production (MLOps) Specialization" provides good background

---

## Meta MLE E4 Interview [Upleveled]
**URL:** https://www.teamblind.com/post/Meta-MLE-E4-Interview-%5BUpleveled%5D-BvRrebh6
**Summary:** A candidate who interviewed for Meta MLE at E4 level received a verbal offer and was upleveled to E5 after a 2+ month interview process. They share that the system design portion was 90% ML-based, covering the entire ML pipeline. The candidate sacrificed their entire holiday period preparing for the interview.
**Interview Questions Mentioned:**
- ML system design covering the full pipeline: feature engineering, dataset generation, labeling, modeling, deployment, and monitoring
- Designing a personalized news ranking system
- Product recommendation system design
- Evaluation frameworks for ads ranking
**Key Insights:**
- Meta rarely uplevels, making E4-to-E5 uplevel notable
- System design at Meta MLE is heavily ML-focused (90%), not generic infrastructure design
- The full ML pipeline (feature engineering through monitoring) must be covered
- Interview process can take over 2 months from start to offer
- Intensive preparation over holidays was key to this candidate's success

---

## Meta MLE E6 ML System Design Interview
**URL:** https://www.teamblind.com/post/meta-mle-e6-ml-system-design-interview-xaoxcs0c
**Summary:** A candidate preparing for the E6-level ML system design round at Meta asks about expectations and time allocation within the 45-minute interview. The discussion focuses on how much time to spend on ML models versus the training/inference pipeline, with a specific question about designing a recommendation system for Facebook posts.
**Interview Questions Mentioned:**
- Design a recommendation system for Facebook posts
- Multi-stage recommender system architecture
- Two-tower, DCN, and multi-task architecture comparisons
**Key Insights:**
- About 10 minutes should be spent on data and feature engineering
- The bulk of the interview should focus on modeling architectures and their tradeoffs
- Multi-stage recommender architecture knowledge is critical (candidate retrieval, ranking, re-ranking)
- Key areas to cover: ML objective definition, data, features, models, offline/online metrics, pipelines, deployment
- Alex Xu's ML System Design book is recommended alongside staying current with research papers

---

## Meta ML Engineer Interview Preparation
**URL:** https://www.teamblind.com/post/meta-ml-engineer-interview-preparation-GDmo5Xxo
**Summary:** A detailed preparation guide shared by a candidate who went through Meta's ML Engineer interview process. The post covers preparation strategies for all rounds including ML system design, behavioral, and coding, with specific resource recommendations and study approaches.
**Interview Questions Mentioned:**
- ML system design questions
- Behavioral questions about Meta values
- LeetCode coding problems (high-frequency Facebook-tagged questions)
**Key Insights:**
- For ML system design: Facebook ML Field Guide and Educative.io ML system design course are primary resources
- For behavioral: read Meta values from Facebook careers site; prepare stories for common scenarios
- For coding: focus on high-frequency LeetCode questions tagged for Facebook from last 6 months
- Author completed approximately 120 medium/hard questions (220 total) for coding preparation
- Blog posts by Rahul Agarwal and others provide useful ML engineer interview perspectives

---

## Meta ML Engineer Interview - PyTorch Team
**URL:** https://www.teamblind.com/post/meta-ml-engineer-interview-pytorch-team-xbgn0mxj
**Summary:** A candidate discusses their interview experience or preparation for an ML Engineer role specifically on Meta's PyTorch team. The discussion highlights that PyTorch team interviews require strong framework knowledge and that ML coding rounds involving debugging PyTorch models are particularly challenging for candidates who do not work extensively with PyTorch.
**Interview Questions Mentioned:**
- ML coding with debugging PyTorch models
- Standard LeetCode coding questions
- ML system design (recommendation systems)
**Key Insights:**
- PyTorch debugging/coding is reported as particularly challenging in ML coding rounds
- Key skills: proficiency in Python and C/C++, experience with PyTorch, understanding of AI infrastructure
- Meta MLE interviews do not have general system design for MLEs; design is ML-focused
- ML design questions typically ask candidates to explain how to build recommendation systems end-to-end
- Candidates need to explain data collection, labeling, feature engineering, modeling, and deployment

---

## Meta MLE Onsite - My Chance if I Screwed Up 1 Coding Interview
**URL:** https://www.teamblind.com/post/meta-mle-onsite---my-chance-if-i-screwed-up-1-coding-interview-GqHnqCWN
**Summary:** A candidate who performed strongly in 3 out of 4 onsite interviews but struggled in one coding round asks about their chances. They solved both coding problems optimally in one round but had difficulty in another. The community shares experiences about how Meta handles mixed interview performance, including the possibility of additional rounds.
**Interview Questions Mentioned:**
- Coding rounds with optimal solution expectations
- ML system design
- Behavioral round
**Key Insights:**
- If a candidate gets strong positive feedback for 3 rounds but fails 1 coding round, Meta may offer an additional coding round for more signal
- Meta sometimes moves forward and accepts candidates despite one weak round
- Strong performance across other dimensions can compensate for one weak coding round
- Google has a similar approach: weak coding in one round may trigger an extra coding round
- Overall signal across all rounds matters more than any single round

---

## Meta ML System Design Interview
**URL:** https://www.teamblind.com/post/meta-ml-system-design-interview-zi15zjvr
**Summary:** A discussion about expectations and preparation strategies for Meta's ML system design interview round. The thread covers how to structure the 45-minute interview, what to prioritize, and which modeling architectures to focus on. Community members emphasize that the focus should be on modeling architectures and their tradeoffs.
**Interview Questions Mentioned:**
- Recommendation system design with multi-stage architecture
- Two-tower vs DCN vs multi-task architecture comparisons
- Questions about system constraints: scale of users, posts, SLAs, personalization, locale/language
**Key Insights:**
- Ask clarifying questions about system constraints: user scale, post scale, SLAs, personalization, locale/language, input modes
- Spend about 10 minutes on data and feature engineering
- Bulk of the interview should focus on modeling architectures and tradeoffs
- Must cover: ML objective, data, features, models, offline/online metrics, pipelines, deployment in 35+ minutes
- Alex Xu's ML System Design book is highly recommended

---

## Meta Research Engineer Interview
**URL:** https://www.teamblind.com/post/meta-research-engineer-interview-z6rumwvd
**Summary:** A candidate discusses the interview process for a Meta Research Engineer position, asking about what to expect in terms of round structure. The community clarifies the typical loop for research engineers, which differs somewhat from standard MLE interviews by potentially including AI-specific coding rounds.
**Interview Questions Mentioned:**
- AI Coding round (math/stats-flavored coding)
- AI System Design round
- Standard coding (LeetCode Easy and Medium)
- Behavioral round
**Key Insights:**
- Research Engineer loop: 1-2 coding rounds (one may be "AI Coding"), 1-2 system design rounds (one being "AI System Design")
- Some candidates report: 2 coding, 1 behavioral, 1 ML research, 1 ML system design
- AI Coding rounds are a newer addition that add mathematical/statistical flavor to problems
- Meta expects optimized solutions even at Easy/Medium difficulty levels
- Interview structure may vary based on specific team and role within research

---

## Microsoft AI Interview Process, Role, and Comp
**URL:** https://www.teamblind.com/post/microsoft-ai-interview-process-role-and-comp-2n7mn3nb
**Summary:** A candidate was contacted by Microsoft AI under Mustafa Suleyman's organization for their Gen AI Infra subteam. The recruiter was vague about the level, specific role details, and compensation, only saying it would be "very competitive." The candidate was bucketed into one of 8-9 different backend role profiles.
**Interview Questions Mentioned:**
- Technical screen: LeetCode medium-level problem
- Role-specific technical rounds (details not well documented due to secretive process)
**Key Insights:**
- Microsoft AI under Mustafa has separate compensation bands from the rest of Microsoft
- They have poached talent from OpenAI and Anthropic, suggesting competitive pay
- The hiring process is notably opaque about leveling and specific compensation
- Candidates are bucketed into one of 8-9 different backend role profiles
- The recruiter experience was described as vague and lacking transparency

---

## ML Architecture Databricks Interview
**URL:** https://www.teamblind.com/post/ML-architecture-Databricks-interview-peyKAk2s
**Summary:** A candidate discusses the ML architecture interview round at Databricks, which focuses on real-world ML system design blending methodology and engineering considerations. The round covers end-to-end ML system design including data sourcing, algorithm design, computational complexity, operations, service efficiency, and user experience.
**Interview Questions Mentioned:**
- Design an end-to-end ML system for a real-world problem
- Data sourcing and curation strategies
- Algorithm design and selection with computational complexity considerations
- Model deployment meeting latency/availability criteria
- Feature store design and training-serving skew prevention
**Key Insights:**
- Databricks ML architecture interviews blend methodological and engineering considerations
- Must formulate the problem, design an ML model, and deploy it to meet latency/availability criteria
- MLflow is central to Databricks ML pipelines for experiment tracking, metrics, and model versioning
- Feature store knowledge is critical for preventing training-serving skew
- Databricks values end-to-end ownership: frame experience from research to deployment, not just modeling
- Be ready to discuss batch scoring vs real-time inference tradeoffs

---

## ML Coding/Assignment Interview for Glean Senior ML Engineer
**URL:** https://www.teamblind.com/post/ml-codingassignment-interview-for-glean-senior-ml-engineer-7fi1gn8f
**Summary:** A candidate with 8 years of experience (TC 1.25 Cr in India) asks about Glean's 2-hour assignment interview for a Senior ML Engineer position, specifically whether candidates implement basic algorithms from scratch or solve real problems using libraries. The discussion covers Glean's unique multi-round interview format.
**Interview Questions Mentioned:**
- 2-hour coding assignment (multi-part low-level design problem)
- Example: coding a table module from scratch, progressing from basics (add rows/columns) to complex features (joins)
- 45-minute algorithmic coding section
- 1-hour LeetCode-style problem
- 1-hour system design round
**Key Insights:**
- Glean has a distinctive 2-hour coding assignment round unlike most companies
- The assignment may be a multi-part low-level design problem, not pure algorithms
- Full interview loop: algorithmic coding (45 min), LeetCode (1 hr), system design (1 hr), coding assignment (2 hr)
- The assignment tests practical engineering skills, not just algorithm implementation
- India-based candidates (1.25 Cr TC) are actively interviewing for these roles

---

## ML Coding Interview at OpenAI and Meta GenAI
**URL:** https://www.teamblind.com/post/ml-coding-interview-at-openai-and-meta-genai-dhq0gysn
**Summary:** A candidate interviewing for Research Engineer positions at both OpenAI and Meta GenAI asks about what to expect in ML coding rounds and what resources to use for preparation. The discussion reveals that ML coding rounds at these companies can involve debugging PyTorch models, which is notably challenging.
**Interview Questions Mentioned:**
- ML coding with debugging PyTorch models
- Research Engineer technical coding questions
- ML implementation questions
**Key Insights:**
- ML coding rounds at OpenAI and Meta GenAI can involve debugging PyTorch models
- PyTorch debugging was described as "hard af, especially if you don't work a lot in PyTorch"
- These are Research Engineer positions, not standard SWE roles
- Practical PyTorch experience is critical for these roles
- Both companies are hiring for GenAI-focused positions with similar technical expectations

---

## ML Coding Interview at Uber
**URL:** https://www.teamblind.com/post/ML-coding-interview-at-Uber-wO1XnWpj
**Summary:** A candidate asks about Uber's ML coding interview round, seeking specifics on what types of questions to expect. The community speculates and shares experiences about implementing ML algorithms from scratch, with typical questions involving coding basic algorithms like k-means, KNN, AUC computation, and gradient descent.
**Interview Questions Mentioned:**
- Implement K-Means from scratch
- Implement KNN from scratch
- Code AUC metric from scratch using vanilla Python
- Implement a single gradient descent step
- Code linear regression / logistic regression from scratch
**Key Insights:**
- Uber's ML coding round focuses on implementing ML algorithms from scratch, not LeetCode
- Common algorithms tested: KNN, K-Means, gradient descent, log loss, linear regression, logistic regression
- Similar to LinkedIn's approach of asking candidates to develop algorithms from scratch
- Only a limited set of algorithms can realistically be asked in interview time constraints
- Preparation tip: practice implementing KNN, K-Means, gradient descent, log loss, linear/logistic regression

---

## MLE Interview Preparation That Led to Successful Offers
**URL:** https://www.teamblind.com/post/mle-interview-preparation-that-led-to-successful-offers-3k2az8d8
**Summary:** A candidate with 5 years of experience and a PhD shares the resources and strategy that led to 4 offers (Apple, Meta, LinkedIn, and a pre-IPO startup) after 4 onsites. Their TC jumped from $215k to $450k, targeting E5/IC5 MLE roles. The post provides a comprehensive breakdown of preparation resources by interview category.
**Interview Questions Mentioned:**
- ML system design (recommendation systems, ranking)
- Behavioral questions (challenges, mistakes/failures, leadership, conflicts)
- Coding interviews (LeetCode style)
- ML theory questions (model selection, regularization, algorithms)
**Key Insights:**
- "Machine Learning Engineering" by Andriy Burkov (mlebook.com) provides excellent theory and practice overview for MLE
- For behavioral: create a table of 3 projects with aspects like challenges, mistakes/failures, leadership, conflicts
- Use STAR method (Situation, Task, Action, Result) for behavioral answers
- 4/4 onsite-to-offer conversion rate with thorough preparation
- TC increase from $215k to $450k demonstrates the value of structured interview prep
- Book covers important topics like data drift and model monitoring

---

## ML Engineer Interview at LinkedIn
**URL:** https://www.teamblind.com/post/ml-engineer-interview-at-linkedin-8us2r5wn
**Summary:** A detailed breakdown of LinkedIn's ML Engineer interview process, covering the screening round, ML concept questions, coding rounds, and ML design round. The community provides specific preparation advice including algorithm implementation expectations and mathematical depth requirements.
**Interview Questions Mentioned:**
- Screening: basic algorithm implementation (KNN, logistic regression, tree algorithms)
- ML concepts: detailed algorithm explanations including mathematical foundations, SGD variants
- Probability questions
- Coding: top 50 LeetCode algorithms by frequency (6 months), including hard problems as follow-ups
- ML design: recommendation systems, search systems, binary classification models
**Key Insights:**
- LinkedIn emphasizes mathematical depth: understand how algorithms work mathematically, especially SGD variants
- Two coding rounds covering top 50 LeetCode by frequency; hard problems can appear as follow-ups
- ML design focuses on recommendation, search, and binary classification
- Probability questions may appear but are not deal-breakers if other ML questions are answered well
- Going deep into mathematical foundations sets candidates apart

---

## ML Engineer Role at DoorDash
**URL:** https://www.teamblind.com/post/ml-engineer-role-at-doordash-bexoggvc
**Summary:** A candidate preparing for a DoorDash ML Engineer interview asks about what to expect in the ML live coding round and project deep dive. The discussion reveals that DoorDash's ML Engineer role is more data-science-oriented than SWE-focused, with significant emphasis on A/B testing, and that teams operate at a fast pace with weekly releases.
**Interview Questions Mentioned:**
- ML live coding (Python, SQL, or pseudocode)
- Project deep dive (problem definition, solution design, outcome, takeaways)
- A/B testing questions (design, analysis, statistical significance)
- Predicting delivery time, identifying fraudulent behavior, optimizing ranking algorithms
**Key Insights:**
- DoorDash ML Engineer is closer to a data science role than a traditional SWE-based MLE
- Candidates get grilled on A/B testing; this is a major focus area
- Project deep dive covers: what's the problem, how you design solutions, how you choose solutions, outcome, takeaways
- ML teams release weekly with models retraining automatically on new data
- Online feature stores, real-time click logging, and A/B infrastructure knowledge is important
- Average time from application to hire is approximately 14 days

---

## ML Engineer - Round 1 Interview at META
**URL:** https://www.teamblind.com/post/ML-engineer---Round-1-Interview-at-META-6w3HHJSP
**Summary:** A candidate without a traditional SWE background (currently working as a data scientist in analytics) asks about preparing for their first round pair programming interview for an ML Engineer role at Meta. They mention being willing to pay for mock interview practice, reflecting the anxiety many non-SWE candidates feel about coding interviews.
**Interview Questions Mentioned:**
- Pair programming coding round
- LeetCode-style problems (top 100 frequent Facebook-tagged, Blind 75 list)
- ML system design (classic recommendation systems)
**Key Insights:**
- The MLE loop is essentially the same as SWE loop with an added ML round
- LeetCode mastery is essential: top 100 Facebook-tagged questions and Blind 75 list recommended
- Coding: 2-3 LC medium Meta-tagged questions per round
- No traditional system design; replaced by ML system design (recommendation systems)
- No separate ML algorithm questions in the coding portion
- Candidates from DS/analytics backgrounds face a steeper curve on the coding component

---

## My Experience Interviewing in 2025
**URL:** https://www.teamblind.com/post/my-experience-interviewing-in-2025-evr4qbcu
**Summary:** A senior engineer with less than 10 years of experience shares their 2025 interview journey, ultimately receiving offers from Figma (~$500k TC) and Meta. They also went through processes at Palantir, Chronosphere, Netflix, and Confluent. The post provides broad observations about the 2025 job market and practical interview preparation advice.
**Interview Questions Mentioned:**
- Coding: LeetCode top 200 problems (sufficient for Meta)
- System design (heavily weighted at senior+ levels)
- Behavioral interviews (connecting experience with theory)
**Key Insights:**
- Referrals are the most effective way to get interviews; cold applications rarely worked
- Job market is strong for senior+ roles with domain experience in AI, ML, infrastructure, systems, and UI/UX
- Coding questions are less random-algorithm-focused than expected (except possibly Meta)
- Top 200 LeetCode problems are more than sufficient for Meta coding rounds
- System design and behavioral have much more weight at senior+ levels
- What differentiates candidates: connecting personal experience with theory and showcasing excellent communication
- Figma offered ~$500k TC for senior engineer level

---

## My xAI Interview Experience - The Most Chaotic Interview Process I've Ever Seen
**URL:** https://www.teamblind.com/post/my-xai-interview-experience-the-most-chaotic-interview-process-ive-ever-seen-tpfjs77c
**Summary:** A candidate describes xAI's interview process as the most chaotic they have ever experienced. After passing the initial call, their onsite was suddenly canceled due to a "project push," followed by weeks of silence, a new requirement for a 10-minute hiring manager intro call, and then three last-minute postponements of that call. Other candidates corroborate similar experiences.
**Interview Questions Mentioned:**
- Initial screening call (technical)
- Onsite interview (scheduled but canceled)
- Hiring manager intro call (10 minutes, postponed repeatedly)
**Key Insights:**
- xAI's interview process is described as messy and unprofessional
- Onsites get suddenly canceled due to internal "project pushes"
- The hiring manager intro call was postponed three times at the last minute
- Other candidates report similar experiences: interviews rescheduled 3+ times with interviewers ghosting
- The company reportedly does not apologize for communication failures
- This pattern suggests systemic issues with xAI's interview coordination, not isolated incidents

---
