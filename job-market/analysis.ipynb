{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# AI Engineering Jobs Analysis\n",
    "\n",
    "Analysis of 895 job descriptions extracted from builtin.com.\n",
    "\n",
    "Searched for jobs containing \"AI Engineer\" keyword from LA, NY, London, Amsterdam and Berlin for last 4 weeks. Done at the beginning of February 2026, so it mostly contains jobs published in January 2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all structured YAML files into a flat DataFrame\n",
    "STRUCTURED_DIR = Path('data_structured')\n",
    "\n",
    "records = []\n",
    "for file in STRUCTURED_DIR.glob('*.yaml'):\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            job = yaml.safe_load(f)\n",
    "        pos = job.get('position', {})\n",
    "        comp = job.get('company', {})\n",
    "        skills = pos.get('skills', {})\n",
    "        records.append({\n",
    "            'job_id': job.get('meta', {}).get('job_id', ''),\n",
    "            'company': comp.get('name', ''),\n",
    "            'stage': comp.get('stage', ''),\n",
    "            'focus': comp.get('focus', ''),\n",
    "            'title': pos.get('title', ''),\n",
    "            'ai_type': pos.get('ai_type', {}).get('type', 'unknown'),\n",
    "            'is_customer_facing': pos.get('is_customer_facing', False),\n",
    "            'is_management': pos.get('is_management', False),\n",
    "            'responsibilities': pos.get('responsibilities', []),\n",
    "            'use_cases': comp.get('use_cases', pos.get('use_cases', [])),\n",
    "            'skills_genai': skills.get('genai', []),\n",
    "            'skills_ml': skills.get('ml', []),\n",
    "            'skills_web': skills.get('web', []),\n",
    "            'skills_databases': skills.get('databases', []),\n",
    "            'skills_data': skills.get('data', []),\n",
    "            'skills_cloud': skills.get('cloud', []),\n",
    "            'skills_ops': skills.get('ops', []),\n",
    "            'skills_languages': skills.get('languages', []),\n",
    "            'skills_domains': skills.get('domains', []),\n",
    "            'skills_other': skills.get('other', []),\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f'Error loading {file}: {e}')\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Ensure list columns are actually lists\n",
    "list_cols = [c for c in df.columns if c.startswith('skills_')] + ['responsibilities', 'use_cases']\n",
    "for col in list_cols:\n",
    "    df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "print(f'Loaded {len(df)} jobs')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: explode a skill list column into counts\n",
    "def skill_counts(df_subset, col):\n",
    "    return df_subset[col].explode().dropna().value_counts()\n",
    "\n",
    "# Helper: count jobs that have a specific skill (substring match) across all skill columns\n",
    "def jobs_with_skill(df_subset, skill_name):\n",
    "    skill_lower = skill_name.lower()\n",
    "    mask = df_subset.apply(\n",
    "        lambda row: any(\n",
    "            skill_lower in s.lower()\n",
    "            for col in SKILL_COLS\n",
    "            for s in (row[col] if isinstance(row[col], list) else [])\n",
    "        ), axis=1\n",
    "    )\n",
    "    return mask.sum()\n",
    "\n",
    "SKILL_COLS = [c for c in df.columns if c.startswith('skills_')]\n",
    "\n",
    "def all_skills_lower(row):\n",
    "    \"\"\"Get all skills from a row as lowercase strings.\"\"\"\n",
    "    out = []\n",
    "    for col in SKILL_COLS:\n",
    "        if isinstance(row[col], list):\n",
    "            out.extend(s.lower() for s in row[col])\n",
    "    return out\n",
    "\n",
    "# Subsets\n",
    "ai_first = df[df['ai_type'] == 'ai-first']\n",
    "ai_support = df[df['ai_type'] == 'ai-support']\n",
    "ml_first = df[df['ai_type'] == 'ml-first']\n",
    "\n",
    "print(f'AI-First: {len(ai_first)}, AI-Support: {len(ai_support)}, ML: {len(ml_first)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-ai-types",
   "metadata": {},
   "source": [
    "## Job Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ai-types",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts = df['ai_type'].value_counts()\n",
    "type_pct = (type_counts / len(df) * 100).round(1)\n",
    "pd.DataFrame({'jobs': type_counts, '%': type_pct})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-companies",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "companies",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Unique companies: {df[\"company\"].nunique()}')\n",
    "print(f'\\nTop 20 companies by job count:')\n",
    "df['company'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "company-stages",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_counts = df[df['stage'] != '']['stage'].value_counts()\n",
    "stage_pct = (stage_counts / len(df) * 100).round(1)\n",
    "pd.DataFrame({'jobs': stage_counts, '%': stage_pct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roles",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Customer-facing roles: {df[\"is_customer_facing\"].sum()} ({df[\"is_customer_facing\"].mean()*100:.1f}%)')\n",
    "print(f'Management roles: {df[\"is_management\"].sum()} ({df[\"is_management\"].mean()*100:.1f}%)')\n",
    "print(f'\\nMost common job titles:')\n",
    "df['title'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-skills",
   "metadata": {},
   "source": [
    "## Skills Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-genai",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "genai = skill_counts(df, 'skills_genai')\n",
    "print('Top GenAI skills:')\n",
    "pd.DataFrame({'jobs': genai.head(10), '%': (genai.head(10) / n * 100).round(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-ml",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top ML skills:')\n",
    "skill_counts(df, 'skills_ml').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-web",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top web skills:')\n",
    "skill_counts(df, 'skills_web').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top database skills:')\n",
    "skill_counts(df, 'skills_databases').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top cloud skills:')\n",
    "skill_counts(df, 'skills_cloud').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-ops",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top ops skills:')\n",
    "skill_counts(df, 'skills_ops').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skills-languages",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = skill_counts(df, 'skills_languages')\n",
    "print('Top languages:')\n",
    "pd.DataFrame({'jobs': langs.head(10), '%': (langs.head(10) / n * 100).round(1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-frameworks",
   "metadata": {},
   "source": [
    "## GenAI Framework Ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frameworks",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameworks = ['LangChain', 'LangGraph', 'LlamaIndex', 'CrewAI', 'AutoGen']\n",
    "genai_all = skill_counts(df, 'skills_genai')\n",
    "fw = genai_all[genai_all.index.isin(frameworks)].reindex(frameworks).dropna().astype(int)\n",
    "pd.DataFrame({'jobs': fw, '%': (fw / n * 100).round(1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-support",
   "metadata": {},
   "source": [
    "## Supporting Roles: What AI-Support Engineers Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "support-categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_support_role(row):\n",
    "    title = row['title'].lower()\n",
    "    resp = ' '.join(row['responsibilities']).lower()\n",
    "    categories = {\n",
    "        'Platform/Infrastructure': ['platform', 'infrastructure', 'infra', 'mlops', 'kubernetes', 'k8s', 'deployment'],\n",
    "        'Data/Pipelines': ['data engineer', 'data pipeline', 'etl', 'data platform'],\n",
    "        'Sales/Solutions': ['sales', 'solutions', 'presales', 'customer success'],\n",
    "        'Backend/General SWE': ['backend', 'api', 'microservices', 'internal tools'],\n",
    "        'Frontend/UI': ['frontend', 'ui', 'ux', 'full-stack'],\n",
    "    }\n",
    "    for cat, keywords in categories.items():\n",
    "        if any(kw in title or kw in resp for kw in keywords):\n",
    "            return cat\n",
    "    return 'Other'\n",
    "\n",
    "support = ai_support.copy()\n",
    "support['category'] = support.apply(categorize_support_role, axis=1)\n",
    "\n",
    "print(f'{len(ai_support)} jobs ({len(ai_support)/len(df)*100:.1f}%) classified as AI-Support\\n')\n",
    "support['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "support-genai-knowledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do AI-Support roles need GenAI knowledge?\n",
    "has_genai = ai_support['skills_genai'].apply(len) > 0\n",
    "print(f'AI-Support roles with GenAI skills: {has_genai.sum()}/{len(ai_support)} ({has_genai.mean()*100:.1f}%)')\n",
    "print(f'AI-Support roles without GenAI skills: {(~has_genai).sum()}/{len(ai_support)} ({(~has_genai).mean()*100:.1f}%)')\n",
    "\n",
    "print('\\nGenAI skills in AI-Support roles:')\n",
    "support_genai = skill_counts(ai_support, 'skills_genai')\n",
    "pd.DataFrame({'jobs': support_genai.head(10), '%': (support_genai.head(10) / len(ai_support) * 100).round(1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-skill-comparison",
   "metadata": {},
   "source": [
    "### Skill Comparison: AI-First vs AI-Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skill-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_skills = ['RAG', 'prompt engineering', 'agents', 'LangChain', 'Docker', 'Kubernetes', 'AWS', 'React']\n",
    "\n",
    "rows = []\n",
    "for skill in compare_skills:\n",
    "    af = jobs_with_skill(ai_first, skill)\n",
    "    asp = jobs_with_skill(ai_support, skill)\n",
    "    rows.append({\n",
    "        'skill': skill,\n",
    "        'AI-First': f'{af/len(ai_first)*100:.1f}%',\n",
    "        'AI-Support': f'{asp/len(ai_support)*100:.1f}%',\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows).set_index('skill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-research",
   "metadata": {},
   "source": [
    "## Research vs Applied Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_research_role(row):\n",
    "    title = row['title'].lower()\n",
    "    resp = ' '.join(row['responsibilities']).lower()\n",
    "    use_cases = ' '.join(row['use_cases']).lower()\n",
    "\n",
    "    research_indicators = [\n",
    "        'research', 'scientist', 'publication', 'paper', 'novel',\n",
    "        'algorithm', 'architecture development', 'model architecture',\n",
    "        'training methods', 'safety research', 'rl research',\n",
    "        'reinforcement learning', 'world model', 'control theory',\n",
    "        'experimental', 'push sota', 'state of the art'\n",
    "    ]\n",
    "    non_research_indicators = [\n",
    "        'production', 'deploy', 'shipping', 'product',\n",
    "        'customer', 'enterprise', 'api integration',\n",
    "        'fine-tuning existing', 'apply', 'implement'\n",
    "    ]\n",
    "\n",
    "    if any(kw in title for kw in ['research engineer', 'scientist', 'research scientist']):\n",
    "        return True\n",
    "\n",
    "    all_text = f'{resp} {use_cases}'\n",
    "    r_score = sum(1 for kw in research_indicators if kw in all_text)\n",
    "    nr_score = sum(1 for kw in non_research_indicators if kw in all_text)\n",
    "    return r_score > nr_score and r_score >= 2\n",
    "\n",
    "df['is_research'] = df.apply(is_research_role, axis=1)\n",
    "research_count = df['is_research'].sum()\n",
    "\n",
    "pd.DataFrame([\n",
    "    {'Role Type': 'Research', 'Jobs': research_count, '%': f'{research_count/len(df)*100:.1f}%'},\n",
    "    {'Role Type': 'Applied/Production', 'Jobs': len(df) - research_count, '%': f'{(len(df)-research_count)/len(df)*100:.1f}%'},\n",
    "]).set_index('Role Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "research-titles",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample research titles:')\n",
    "df[df['is_research']]['title'].drop_duplicates().head(15).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-titles",
   "metadata": {},
   "source": [
    "## What Other Titles Do \"AI Engineers\" Go Under?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "title-clusters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(title):\n",
    "    t = title.lower()\n",
    "    for kw in ['senior', 'staff', 'principal', 'lead', 'junior', 'sr.', 'sr', 'iii', 'ii']:\n",
    "        t = t.replace(kw, '').strip()\n",
    "    return ' '.join(t.split())\n",
    "\n",
    "df['norm_title'] = df['title'].apply(normalize_title)\n",
    "\n",
    "# Group by normalized title and ai_type\n",
    "title_groups = df.groupby('norm_title')['ai_type'].value_counts().unstack(fill_value=0)\n",
    "title_groups['total'] = title_groups.sum(axis=1)\n",
    "title_groups = title_groups[title_groups['total'] >= 3]\n",
    "\n",
    "# Strongly AI-First titles (75%+)\n",
    "if 'ai-first' in title_groups.columns:\n",
    "    title_groups['ai_first_pct'] = (title_groups['ai-first'] / title_groups['total'] * 100).round(0)\n",
    "    strongly_ai_first = title_groups[title_groups['ai_first_pct'] >= 75].sort_values('total', ascending=False)\n",
    "    print('Strongly AI-First titles (75%+ AI-First):')\n",
    "    print(strongly_ai_first[['total', 'ai_first_pct']].head(10).to_string())\n",
    "\n",
    "# Strongly AI-Support titles (75%+)\n",
    "if 'ai-support' in title_groups.columns:\n",
    "    title_groups['ai_support_pct'] = (title_groups['ai-support'] / title_groups['total'] * 100).round(0)\n",
    "    strongly_support = title_groups[title_groups['ai_support_pct'] >= 75].sort_values('total', ascending=False)\n",
    "    print('\\nStrongly AI-Support titles (75%+ AI-Support):')\n",
    "    print(strongly_support[['total', 'ai_support_pct']].head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-ml-knowledge",
   "metadata": {},
   "source": [
    "## How Much ML Do AI Engineers Need to Know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-knowledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_skills_list = [\n",
    "    'PyTorch', 'TensorFlow', 'Keras', 'JAX', 'scikit-learn', 'XGBoost',\n",
    "    'LightGBM', 'fine-tuning', 'model training', 'model evaluation',\n",
    "    'embeddings', 'deep learning', 'machine learning', 'neural networks',\n",
    "    'optimization', 'CUDA', 'transformers', 'huggingface'\n",
    "]\n",
    "\n",
    "def has_any_ml_skill(row):\n",
    "    skills = all_skills_lower(row)\n",
    "    return any(ml.lower() in s for s in skills for ml in ml_skills_list)\n",
    "\n",
    "ai_first_ml = ai_first.apply(has_any_ml_skill, axis=1)\n",
    "print(f'{ai_first_ml.mean()*100:.1f}% of AI-First roles require some ML knowledge')\n",
    "\n",
    "# Most common ML skills in AI-First roles\n",
    "def count_ml_skill(skill_name):\n",
    "    skill_lower = skill_name.lower()\n",
    "    return ai_first.apply(\n",
    "        lambda row: any(skill_lower in s for s in all_skills_lower(row)), axis=1\n",
    "    ).sum()\n",
    "\n",
    "ml_counts = {s: count_ml_skill(s) for s in ml_skills_list}\n",
    "ml_df = pd.Series(ml_counts).sort_values(ascending=False)\n",
    "ml_df = ml_df[ml_df > 0]\n",
    "pd.DataFrame({'jobs': ml_df, '%': (ml_df / len(ai_first) * 100).round(1)}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-non-genai",
   "metadata": {},
   "source": [
    "## What Else (Besides GenAI) Do AI Engineers Need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "non-genai-skills",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_af = len(ai_first)\n",
    "\n",
    "has_genai_col = ai_first['skills_genai'].apply(len) > 0\n",
    "has_ml = ai_first['skills_ml'].apply(len) > 0\n",
    "has_web = ai_first['skills_web'].apply(len) > 0\n",
    "has_ops = ai_first['skills_ops'].apply(len) > 0\n",
    "has_cloud = ai_first['skills_cloud'].apply(len) > 0\n",
    "has_data = ai_first['skills_data'].apply(len) > 0\n",
    "has_db = ai_first['skills_databases'].apply(len) > 0\n",
    "has_any_other = has_ml | has_web | has_ops | has_cloud | has_data | has_db\n",
    "\n",
    "combos = {\n",
    "    'GenAI + Ops (Docker, K8s, CI/CD)': (has_genai_col & has_ops).sum(),\n",
    "    'GenAI + ML skills': (has_genai_col & has_ml).sum(),\n",
    "    'GenAI + Web skills': (has_genai_col & has_web).sum(),\n",
    "    'GenAI + ANY other tech': (has_genai_col & has_any_other).sum(),\n",
    "    'Pure GenAI (nothing else)': (has_genai_col & ~has_any_other).sum(),\n",
    "}\n",
    "\n",
    "combo_df = pd.Series(combos)\n",
    "pd.DataFrame({'jobs': combo_df, '%': (combo_df / n_af * 100).round(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "non-genai-by-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-GenAI skills by category for AI-First roles\n",
    "for cat in ['web', 'cloud', 'ops', 'languages', 'databases', 'data']:\n",
    "    col = f'skills_{cat}'\n",
    "    counts = skill_counts(ai_first, col)\n",
    "    if len(counts) > 0:\n",
    "        top = counts.head(6)\n",
    "        pcts = (top / n_af * 100).round(1)\n",
    "        print(f'\\n{cat.upper()}:')\n",
    "        for skill, count in top.items():\n",
    "            print(f'  {skill}: {count} ({pcts[skill]}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fullstack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-stack expectations for AI-First roles\n",
    "def has_frontend_skills(row):\n",
    "    skills = all_skills_lower(row)\n",
    "    return any(kw in s for s in skills for kw in ['react', 'vue', 'next.js', 'frontend', 'typescript', 'javascript'])\n",
    "\n",
    "def has_backend_skills(row):\n",
    "    skills = all_skills_lower(row)\n",
    "    return any(kw in s for s in skills for kw in ['fastapi', 'flask', 'django', 'api', 'graphql', 'rest'])\n",
    "\n",
    "fe = ai_first.apply(has_frontend_skills, axis=1)\n",
    "be = ai_first.apply(has_backend_skills, axis=1)\n",
    "fs = fe & be\n",
    "\n",
    "print(f'Frontend skills: {fe.sum()}/{n_af} ({fe.mean()*100:.1f}%)')\n",
    "print(f'Backend skills: {be.sum()}/{n_af} ({be.mean()*100:.1f}%)')\n",
    "print(f'Full-stack (both): {fs.sum()}/{n_af} ({fs.mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-finetuning",
   "metadata": {},
   "source": [
    "## Fine-Tuning Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finetuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_keywords = ['fine-tun', 'finetun', 'fine tun', 'custom model', 'specialized model',\n",
    "               'domain-specific', 'adaptation', 'lora', 'qlora', 'peft', 'instruction tuning']\n",
    "\n",
    "def get_all_text(row):\n",
    "    parts = [row['title'], ' '.join(row['responsibilities']), ' '.join(row['use_cases'])]\n",
    "    for col in SKILL_COLS:\n",
    "        if isinstance(row[col], list):\n",
    "            parts.extend(row[col])\n",
    "    return ' '.join(parts).lower()\n",
    "\n",
    "ai_first_texts = ai_first.apply(get_all_text, axis=1)\n",
    "has_ft = ai_first_texts.apply(lambda t: any(kw in t for kw in ft_keywords))\n",
    "\n",
    "print(f'{has_ft.mean()*100:.1f}% of AI-First roles mention fine-tuning')\n",
    "\n",
    "# Depth of fine-tuning\n",
    "primary_ft_kw = ['lora', 'qlora', 'peft']\n",
    "\n",
    "def ft_depth(text):\n",
    "    if not any(kw in text for kw in ft_keywords):\n",
    "        return 'No FT mentioned'\n",
    "    if any(kw in text for kw in primary_ft_kw) or text.count('fine-tun') + text.count('finetun') >= 2:\n",
    "        return 'Primary FT responsibility'\n",
    "    return 'Secondary/occasional FT'\n",
    "\n",
    "ft_levels = ai_first_texts.apply(ft_depth).value_counts()\n",
    "pd.DataFrame({'jobs': ft_levels, '%': (ft_levels / len(ai_first) * 100).round(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ft-use-cases",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning use cases\n",
    "ft_use_case_categories = {\n",
    "    'Instruction following': ['instruction', 'task', 'command', 'reasoning', 'agent'],\n",
    "    'Domain knowledge': ['domain', 'industry', 'vertical', 'medical', 'legal', 'finance', 'healthcare', 'scientific'],\n",
    "    'Style/Tone': ['style', 'tone', 'voice', 'brand', 'personality', 'format'],\n",
    "    'Company data': ['company', 'internal', 'proprietary', 'organization'],\n",
    "    'Performance': ['faster', 'smaller', 'efficiency', 'latency', 'cost', 'optimize'],\n",
    "    'Language': ['language', 'translation', 'multilingual', 'non-english'],\n",
    "    'Privacy': ['privacy', 'on-premise', 'local', 'offline', 'secure'],\n",
    "}\n",
    "\n",
    "ft_jobs = ai_first[has_ft.values]\n",
    "all_ucs = ft_jobs['use_cases'].explode().dropna()\n",
    "\n",
    "uc_cats = Counter()\n",
    "for uc in all_ucs:\n",
    "    uc_lower = uc.lower()\n",
    "    for cat, kws in ft_use_case_categories.items():\n",
    "        if any(kw in uc_lower for kw in kws):\n",
    "            uc_cats[cat] += 1\n",
    "            break\n",
    "\n",
    "print('Fine-tuning use cases:')\n",
    "for cat, count in sorted(uc_cats.items(), key=lambda x: -x[1]):\n",
    "    print(f'  {cat}: {count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}