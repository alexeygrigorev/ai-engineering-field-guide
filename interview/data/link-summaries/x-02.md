# X/Twitter Link Summaries - Batch 02

---
## kmeanskaran - Indian IT Recruitment and ML Interview Dysfunction

**URL:** https://x.com/kmeanskaran/status/2021913598512242819
**Summary:** Karan criticizes Indian IT recruitment practices where HR interviewers with MBA backgrounds ask technical ML questions like "What is regularization?" and "How do you deploy a model?" without domain knowledge. He argues companies prioritize candidates who answer quickly and show up on time rather than seeking genuine problem-solvers, noting the irony of requiring multiple DSA rounds while never connecting candidates with actual ML team members.
**Interview Questions Mentioned:**
- "What is regularization?"
- "How do you deploy a model?"
**Key Insights:**
- HR gatekeepers with no ML background are screening for technical ML roles
- Speed and availability are weighted over problem-solving ability in many Indian IT hiring processes
- Candidates face DSA rounds as a filter even for ML roles, without subject-matter expert interviews
- The disconnect between recruiter capabilities and role requirements is a systemic issue

---

## omarsar0 - Top 50 LLM Interview Questions Resource

**URL:** https://x.com/omarsar0/status/1930984834454712537
**Summary:** Elvis Saravia (@omarsar0, founder of DAIR.AI, ex-Meta AI) shares what he describes as a great resource: a curated list of 50 LLM interview questions for learning LLM basics. The post received 349K+ views and 2.7K likes, indicating strong community interest in structured LLM interview preparation materials.
**Interview Questions Mentioned:** References a collection of 50 LLM interview questions (image attached, specific questions not extracted from the API response)
**Key Insights:**
- Structured LLM interview question lists are in high demand in the AI community
- Even researchers with strong credentials (PhD, Meta AI, Elastic) are sharing interview prep resources
- The volume of engagement (349K views) reflects how many people are actively preparing for LLM roles
- DAIR.AI is a notable source for democratized AI education and interview prep resources

---

## OsokoyaF - Interview Thread: Prompt Engineering vs Fine-Tuning

**URL:** https://x.com/OsokoyaF/status/2016519979978436904
**Summary:** Osokoya Fiyin opens a thread directly framed as interview preparation, asking candidates to explain the difference between prompt engineering and fine-tuning. The thread is positioned as practical guidance for AI engineering interview candidates on a foundational conceptual distinction.
**Interview Questions Mentioned:**
- "Explain the difference between prompt engineering and fine-tuning."
**Key Insights:**
- Prompt engineering vs. fine-tuning is a common AI engineering interview question
- Understanding when to use each approach (cost, latency, data requirements, task complexity) is key
- The question tests both conceptual knowledge and practical judgment
- Posted in the "Build in Public" community, suggesting grassroots AI education content

---

## prateek_0041 - AI Is Creating Engineers with Shallow Technical Knowledge

**URL:** https://x.com/prateek_0041/status/1945150930330247442
**Summary:** Prateek Singh shares his hiring experience finding that candidates with polished AI-assisted resumes couldn't explain their own code or implement basic extensions in live interviews. He uses a two-stage interview process: an AI-permitted assignment followed by a code explanation and live coding session, revealing that many candidates with 2+ years of experience lack fundamentals like Docker, API fetching, CRUD, and testing basics.
**Interview Questions Mentioned:** Implied: code explanation of submitted assignment, live coding extensions, implementation of utility functions
**Key Insights:**
- AI tools allow candidates to produce polished submissions without understanding the underlying code
- Two-stage interviews (AI-allowed assignment + live explanation) are an effective filter
- Fundamentals expected from engineers with 2+ years: Docker, API fetching, CRUD, documentation, testing
- Interviewers are increasingly using "explain this code you wrote" as a verification step
- The author's advice to candidates: invest in deep technical knowledge, not AI shortcuts
- This is a warning signal for candidates who rely on AI without understanding the output

---

## Pseudo_Sid26 - AI/ML Career Roadmap: Ready vs Aspiration Roles

**URL:** https://x.com/Pseudo_Sid26/status/1983503905943380105
**Summary:** Siddharth maps his current job readiness across AI/ML roles: confident applying for Data Analyst, ML Engineer, Python Backend Engineer, and MLOps Engineer, while identifying Gen AI Engineer, AI Engineer, Applied AI Engineer, and Data Engineer as aspiration roles. He explicitly lists his skills gaps: Databricks, Terraform, LangGraph, LangChain, Agentic RAG, System Design, agent automation tools, and LLMOps.
**Interview Questions Mentioned:** None
**Key Insights:**
- Clear self-assessment of role readiness is a useful career planning framework
- Skills gap for senior AI/Gen AI roles in 2025: LangGraph, LangChain, Agentic RAG, LLMOps, System Design
- Databricks and Terraform appear as data engineering gaps even for AI-focused candidates
- "Applied AI Engineer" and "Agentic" roles require a distinct skill set beyond core ML engineering
- This kind of public skills mapping reflects the community norm of learning in public

---

## pvergadia - Nine-Step AI Engineering Interview Preparation Framework

**URL:** https://x.com/pvergadia/status/2001117645933043781
**Summary:** Priyanka Vergadia (@pvergadia) shares a comprehensive nine-area framework for AI engineering interview preparation, covering the full stack from data engineering and deep learning to model serving, optimization, and AI safety. The post received 544 likes, 612 bookmarks, and 26.5K views, suggesting it's widely used as a reference guide.
**Interview Questions Mentioned:** None as explicit questions, but the framework covers topics commonly tested in interviews
**Key Insights:**
- Nine areas to master for AI engineering interviews: data engineering (SQL, Pandas, Spark), deep learning (PyTorch), LLMs and prompt engineering (CoT, few-shot, LangChain), RAG systems (vector DBs, embeddings), MLOps/CI/CD (MLflow, W&B), fine-tuning (PEFT, LoRA, QLoRA), model serving (FastAPI, Triton, vLLM), optimization/quantization (FP16, INT8, pruning, distillation), AI safety and evaluation (RAGAS, hallucination detection)
- Key advice: "Understand the math, but master the implementation"
- Always question whether an LLM is actually necessary for the problem
- 612 bookmarks suggests this is heavily used for interview prep

---

## _rohit_tiwari_ - Top 50 LLM Interview Questions: Seven Topic Areas

**URL:** https://x.com/_rohit_tiwari_/status/1958163536619712770
**Summary:** Rohit Kumar Tiwari posts a structured breakdown of 50 LLM interview questions across seven categories: core concepts (tokenization, attention, context windows), training methods (LoRA, fine-tuning), text generation (decoding, prompting), math foundations (calculus, loss functions, linear algebra), architectures (transformers, MoE, RAG), applications (model comparisons, foundation models), and practical issues (hyperparameters, bias, deployment). The post received 46K+ views and 814 bookmarks.
**Interview Questions Mentioned:** References 50 LLM interview questions organized across seven topic areas (full PDF available via DM)
**Key Insights:**
- Seven core knowledge areas tested in LLM interviews: core concepts, training, generation, math, architectures, applications, practical issues
- Math foundations (calculus, linear algebra, loss functions) remain expected knowledge for LLM roles
- MoE (Mixture of Experts) is now a mainstream architecture topic in LLM interviews
- Bias mitigation and deployment challenges are included as practical interview topics
- 814 bookmarks indicates this is a heavily referenced interview prep resource

---

## safishamsii - Career Milestone: MS with Distinction + AI Engineer Offer in London

**URL:** https://x.com/safishamsii/status/2014249047138189496
**Summary:** Safi documents their early 2026 career milestones: completing an MS with distinction from the University of Birmingham, receiving multiple AI/ML job offers, and accepting an AI Engineer position at a VC-backed London startup. The post reflects on overcoming rejection through persistence and includes reflections on the job search journey.
**Interview Questions Mentioned:** None
**Key Insights:**
- An MS with distinction is a useful credential for breaking into AI Engineer roles at London startups
- Multiple offers are achievable but require persistence through a high rejection rate
- VC-backed startups are active hirers of new AI engineering graduates in the UK market
- The post reflects a broader pattern: strong academic credentials + persistence = entry into AI roles
- London is an active market for AI engineering roles in 2025-2026

---

## SakanaAILabs - Guide to Preparing for Research Role Applications

**URL:** https://x.com/SakanaAILabs/status/2013431501040263363
**Summary:** Sakana AI (Tokyo-based AI R&D lab) shares an unofficial preparation guide for research role applicants, emphasizing four principles: depth over breadth, questioning the problem space rather than just solving it, explaining reasoning transparently, and showing genuine curiosity rather than just technical competence. The guide targets candidates applying to research positions specifically.
**Interview Questions Mentioned:** None explicit, but the framework implies research interviews test: problem formulation, reasoning transparency, intellectual curiosity
**Key Insights:**
- Research role interviews value depth over broad surface-level knowledge
- Interviewers want candidates who question the problem, not just answer it
- Explaining reasoning process matters as much as reaching the correct answer
- Curiosity and intellectual engagement are evaluated alongside technical ability
- This contrasts with engineering interviews which tend to focus more on implementation
- Sakana AI's framing is useful for anyone targeting AI research roles (vs. applied engineering)

---

## tom_doerr - 300 Real-World ML System Design Case Studies

**URL:** https://x.com/tom_doerr/status/1950807395027882240
**Summary:** Tom Dorr shares a curated list of 300 real-world ML system design case studies, positioning it as a practical resource for interview preparation and learning. The post received modest engagement (17 likes, 3 retweets, 25 bookmarks) but the resource itself — a large collection of production ML case studies — is substantively valuable.
**Interview Questions Mentioned:** None; the resource is a collection of case studies, not questions
**Key Insights:**
- 300 real-world case studies is a substantial resource for ML system design interview preparation
- Real case studies from production systems are more valuable than theoretical design exercises
- System design is a distinct interview stage for ML roles, requiring knowledge of production architectures
- Tom Dorr frequently shares GitHub repositories and curated resources for AI/ML practitioners

---

## va_a14 - LinkedIn ML Engineer Interview Process and Compensation (India)

**URL:** https://x.com/va_a14/status/2008516020215095419
**Summary:** Vaibhav Agarwal details LinkedIn's Machine Learning Engineer interview process and compensation in India (60+ LPA for 2+ years experience, 85+ LPA for senior candidates). The process spans five rounds: screening (DSA, probability, ML fundamentals), AI coding (mathematical problem-solving), DSA (two-pointer, array partitioning), AI fundamentals (embeddings, BERT, regularization), system design (cold-start recommender), and hiring manager behavioral.
**Interview Questions Mentioned:**
- DSA: two-pointer problems, array partitioning via backtracking
- AI fundamentals: embeddings, BERT, regularization techniques
- System design: design a cold-start recommender system
- Screening: probability questions, ML fundamentals
**Key Insights:**
- LinkedIn ML Engineer interviews in India require strong algorithmic skills alongside deep AI theory
- Cold-start recommender system design is a specific system design question used by LinkedIn
- BERT and embeddings are tested as AI fundamentals, not just as LLM topics
- The 5-round structure is: screening + AI coding + DSA + AI fundamentals + system design + behavioral
- Compensation benchmarks: 60+ LPA (2+ years), 85+ LPA (senior) in India

---

## verrsane - Recruiter Role Mismatch: AI Engineer vs ML Engineer

**URL:** https://x.com/verrsane/status/2011562947617939957
**Summary:** An AI engineer (verrsane) describes a frustrating recruiting experience where a recruiter couldn't provide a job description, claimed the role was for an "AI Engineer," but the actual interview turned out to be for an ML Engineer position. The post highlights the persistent confusion between AI Engineer and ML Engineer role definitions in hiring.
**Interview Questions Mentioned:** None
**Key Insights:**
- The AI Engineer vs ML Engineer distinction remains unclear to many recruiters
- Recruiters operating without job descriptions is a common and frustrating pattern
- Role title inflation and mismatch between recruiter descriptions and actual interview scope is widespread
- Candidates should push for job descriptions and role clarity before investing time in interview processes
- This confusion creates friction for candidates trying to target their preparation appropriately

---
