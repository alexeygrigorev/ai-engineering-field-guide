


## Microsoft SWE applied AI/ML summer 2026 Redmond interview experience
**URL:** https://www.reddit.com/r/csMajors/comments/1nqfzhq/microsoft_swe_applied_aiml_summer_2026_redmond
**Summary:** A student shares a detailed account of their Microsoft SWE Applied AI/ML intern interview experience from September 2026, covering all 3 rounds. The process included an Online Assessment (OA) first, followed by a recruiter suggestion to switch from a Full Stack role to the AI/ML role based on their profile. The candidate describes three 45-minute rounds: one focused entirely on using an LLM to code, one on coding without AI assistance, and one behavioral/technical discussion round.
**Interview Questions Mentioned:**
- Round 1 (AI-assisted coding): Reverse a linked list with constraints (LC Easy); interviewer modified the problem and asked candidate to re-prompt the LLM.
- Round 2 (no AI): Find the Excel column name from its column number (e.g., column 702 = "AAA"); construct a tree from a list where index = node value and value = parent node (LC Medium).
- Round 3 (behavioral/technical discussion): Questions about previous experiences, projects, and behavioral questions; one technical discussion problem with no coding.
**Key Insights:**
- Microsoft's Applied AI/ML SWE intern interview explicitly tests how effectively candidates can use LLMs (like ChatGPT) to code — Round 1 is entirely AI-assisted.
- Round 2 directly tests coding ability without AI, ensuring candidates aren't solely dependent on LLM assistance.
- Recruiters may suggest switching a candidate from a generalist role to an AI/ML role based on resume profile — indicating AI/ML roles are being actively filled.
- The format (test AI use AND test coding without AI) signals that Microsoft values both AI-augmented productivity and baseline coding skills.
- The interviewer was positive and gave real-time feedback during the interview.
- Comments confirm: the process did not involve standard LeetCode-style DSA prep as the primary focus.

---

## BCG X AI Engineer Intern summer 2026 Interview
**URL:** https://www.reddit.com/r/csMajors/comments/1pp9jht/bcg_x_ai_engineer_intern_summer_2026_interview
**Summary:** A candidate preparing for a BCG X AI Engineer Intern (Summer 2026) interview asks for insights on the live coding round — specifically whether it focuses on Python data manipulation (pandas/NumPy) or DSA-style problems, or a mix. Comments from peers who went through the process indicate the initial assessment is a CodeSignal GCA (General Coding Assessment), and that a near-perfect score (600/600) is expected to advance.
**Interview Questions Mentioned:** No specific interview questions; OA is CodeSignal GCA format.
**Key Insights:**
- BCG X AI Engineer Intern interviews start with a CodeSignal GCA — a near-perfect score (600/600) appears to be the bar for advancing.
- Candidates are unsure whether subsequent live coding focuses on DSA vs. data manipulation — the format is not clearly communicated ahead of time.
- There are several active parallel threads for BCG X AI Engineer roles (new grad, OA, tech case), indicating high candidate interest.
- Some candidates submitted a previously taken CodeSignal score rather than taking a new test.
- The role and process reflect growing demand for AI engineers at consulting firms alongside traditional tech companies.

---

## Failed an interviewee because they wouldn't shut up about LLMs at the end of the interview
**URL:** https://www.reddit.com/r/datascience/comments/15t69mt/failed_an_interviewee_because_they_wouldnt_shut/
**Summary:** An interviewer shares that they gave a borderline senior candidate a "soft thumbs down" because the candidate kept insisting on discussing how LLMs could help with a regression problem the team was working on, in a way that didn't make sense technically. The post generated significant discussion and humor (parody comments), with the community debating whether this was fair and what the candidate was actually thinking.
**Interview Questions Mentioned:** None (the incident occurred in the Q&A portion at the end of the interview).
**Key Insights:**
- Unprompted LLM hype at the end of an interview — when it's clearly irrelevant to the problem — is a signal that can tip an interviewer from borderline pass to fail.
- The interviewer was themselves in a senior role with less experience than the candidate, highlighting that interview outcomes depend on interpersonal dynamics and context fit, not just ability.
- Common misunderstanding flagged: "auto-regressive" does not mean "good at regression" — commenters suggest this misconception may explain why candidates incorrectly pitch LLMs for regression tasks.
- Top comment deflates the situation: "We are three levels of assumptions deep into a post based off really nothing" — the community is skeptical that the candidate's intent was as bad as presented.
- Being knowledgeable but communicating it poorly (especially if you know more than the interviewer) can still result in rejection.
- For senior roles, the candidate is expected to read the room and demonstrate judgment about when AI solutions are and aren't appropriate.


## Getting Interviews for really Senior roles (Staff Research Scientist), don't understand why and what to do
**URL:** https://www.reddit.com/r/datascience/comments/1g5ilx7/getting_interviews_for_really_senior_roles_staff/
**Summary:** A grad student who worked as a "Founding AI Research Engineer" at an AI agents startup is suddenly receiving interview calls for Principal DS, Senior Staff Research Scientist, and Lead roles at top companies — despite having only ~2.5 years of DS experience (mostly PoC-stage), limited engineering skills, and no production deployment experience. They are panicking ahead of 10+ interviews and don't know how to handle being over-leveled.
**Interview Questions Mentioned:** None (the candidate hasn't had the interviews yet and is seeking advice about how to handle the situation).
**Key Insights:**
- "Founding AI Research Engineer" with LLM/AI agents keywords can cause ATS systems and recruiters to dramatically over-level a candidate's experience.
- AI agents, LLMs, and related buzzwords in a resume are currently causing significant ATS over-scoring regardless of actual depth.
- Interviewers at senior levels will likely uncover the experience mismatch — transparency about seniority and learning trajectory is generally better than trying to fake it.
- The community advice: be honest about your level, focus on your strengths, ask questions about their use of AI to demonstrate genuine curiosity.
- Imposter syndrome is normal at every level — even experienced seniors feel unqualified walking into new roles.
- These interviews are valuable as learning experiences even if you don't land the roles.




## ML Engineer GenAI @ Amazon
**URL:** https://www.reddit.com/r/datascience/comments/1jrdrpx/ml_engineer_genai_amazon/
**Summary:** A candidate preparing for a technical ML Engineer interview at Amazon's GenAI Innovation Center (Senior L6 role) asks whether to focus on GenAI-specific concepts or keep prep broad with traditional ML (PCA, K-means, linear regression). Online resources emphasize general ML but the role description focuses on LLM customization and fine-tuning, making the relevance of classic ML topics unclear.
**Interview Questions Mentioned:**
- Cosine similarity implementation using NumPy basics (asked in phone screen alongside a LeetCode question).
- LeetCode-style DSA questions (confirmed as part of the SDE bar Amazon requires even for MLEs).
- ML system design questions for senior roles.
- Leadership Principles (LP) behavioral questions — Amazon's behavioral interview framework.
**Key Insights:**
- Amazon does not have a dedicated MLE job family — MLEs must pass the standard SDE technical bar including DSA coding (data structures, problem solving, logical/maintainable code).
- For GenAI-specific teams (e.g., Generative AI Innovation Center), the ML functional component likely focuses on GenAI depth: LLM/ViT/DiT architectures, fine-tuning, use case ideation, ROI estimation.
- Traditional ML concepts (PCA, K-means) may or may not appear, depending on the specific team (more likely for SageMaker-adjacent teams).
- Amazon's kitchen-sink approach to Applied Scientist interviews is documented: LeetCode + SQL + ML theory + statistics + case study + LPs can all appear.
- For senior L6 GenAI roles: expect system design, many LP examples, and ability to reason about GenAI business risks, testing strategy, monitoring, and cost/ROI.
- Phone screen included both a LeetCode problem and a practical ML coding question (cosine similarity in NumPy).

---

## Databricks GenAI DS Interview
**URL:** https://www.reddit.com/r/datascience/comments/1jvhdsc/databricks_genai_ds_interview/
**Summary:** A candidate preparing for their 3rd round Databricks interview (GenAI DS role) shares their background in NLP and encoder-only models, and asks for experience reports from others who've interviewed there. They're catching up on decoder architectures and expect fundamentals questions, but want to understand the interview format more concretely.
**Interview Questions Mentioned:** None explicitly shared (the candidate hasn't had the interview yet; a commenter invoked NDA).
**Key Insights:**
- Databricks GenAI DS interviews are described as manageable for candidates with strong programming skills and genuine ML niche expertise (per commenter with NDA restriction).
- Being expert in encoder-only models (NLP background) is a solid foundation, but decoder/autoregressive architecture knowledge is increasingly expected for GenAI roles.
- No DSA rounds confirmed for this role by commenters, but the question was asked, suggesting uncertainty.
- Interview materials provided to the candidate outlined the process but didn't detail specific content closely.
- The 3rd round suggests a multi-stage process: likely phone screen → technical → final loop.

---

## What SWE/AI Engineer skills in 2025 can I learn to complement Data Science?
**URL:** https://www.reddit.com/r/datascience/comments/1k2igce/what_sweai_engineer_skills_in_2025_can_i_learn_to/
**Summary:** A Data Scientist at a company where GenAI work is increasingly handled by SWEs observes that DS projects are declining as "modelling" becomes a GPT/API call that engineers handle. They ask what SWE/AI Engineering skills to learn to stay relevant, integrate GenAI into products, and bridge the gap from DS notebooks to production AI applications.
**Interview Questions Mentioned:** None (this is a skills/career development discussion, not interview-focused).
**Key Insights:**
- A clear signal from industry: DS roles are being displaced at some companies as GenAI makes "modelling" accessible to SWEs via API calls — DS engineers need to move up the stack.
- The key skill gap identified: building and deploying GenAI features in production products (JavaScript ecosystem), beyond Python notebooks.
- Practical path suggested: learn Python web frameworks (FastAPI/Flask), then frontend (JavaScript/React or Python-based Reflex), then integrate with LLM APIs.
- GitHub practices, product thinking, and UX basics were called out as non-technical skills AI Engineers need.
- C++ was mentioned as a high-value but painful path for AI engineers building infrastructure.
- The "DS → AI Engineer" transition requires a mindset shift: "You're not the modeller anymore. You're building product."
- For interviews, this suggests AI Engineering roles increasingly require full-stack awareness, not just ML modeling expertise.
